# Simple contrast coding
Defining a grouping variable
```{julia}
grouped = Dict(:ID => Grouping(), :total_control_loss => Grouping());
```

# Power estimation as Simulation
We already have a tool for simulating: the parametricbootstrap function. It uses by default the estimates (parameters) of the model that fitted to the data. We will assume these are the ground truth. But we can actually take other values and simulate other worlds so to say. 

```{julia}
pb = parametricbootstrap(MersenneTwister(36), 100, m_varyingSlope2; optsum_overrides=(;ftol_rel=1e-8))
```

## Before we run our experiment...
Let's start right at the beginning. We have no data, therefore we simulate some, putting only random noise into it. We use the simdat_crossed function for that.

```{julia}
subj_between = Dict(:age => ["old", "young"])
item_between = Dict(:frequency => ["low", "high"])

subj_n = 30
item_n = 30

sim_dat = simdat_crossed(MersenneTwister(42), subj_n, item_n; subj_btwn=subj_between, item_btwn=item_between)
sim_dat = DataFrame(sim_dat)
sort(sim_dat, [:frequency, :subj])
```

Now we can actually fit a model to the data expecting no effects (because we put none into the data).
```{julia}

```

# Remarks
If there is dispersion in the data and it seems to be gamma distributed, use boxcox transformation on the data.


# If you find out that a single level of a categorical covariate is not having much effect...
## Building a model without input_noiseW
You find that out by building a complex zerocorr model and looking at the VarCorr output. If Variance and Std.Dev. are =0, kick this one level out. 
You do that by appending new columns to your data that simply represent the presence of the individual levels.
```{julia}

test = my_data

mm=modelmatrix(m_varyingSlope_complex)
mm_df=DataFrame(mm, :auto)

test.Intercept = mm_df[:,1];
test.N_obstacles = mm_df[:,2];
test.N_driftTiles = mm_df[:,3];
test.Input_noiseW = mm_df[:,4];
test.Input_noiseS = mm_df[:,5];
test.NobstaclesXNdrift = mm_df[:,6];

```
Now we have a new dataframe called test. We will put the these new columns into the model structure bu can leave out the individual level that has no impact in the random effects structure. We can still put it into the fixed effects structure though.

# Testing models via likelihoodratiotest
testing all models doesn't make so much sense. Slope2 is tested against Slope1 but both have the same number of parameters. Same goes for Slope4 against Slope3. The resulting p-values will be NaN because a significance test won't be possible. It would rather make sense to pass the most complex model first and go from there.

#### Will the variance-covariance matrix be 0.0 everywhere except diagonal when I state zerocorr(random effects)?
```{julia}

m_varyingSlope_zeroCorr = let
    varSlop = @formula(log(fixation_duration) ~ 1 + N_visible_obstacles * N_visible_drift_tiles + input_noise + zerocorr(1 + N_visible_obstacles + N_visible_drift_tiles + input_noise | ID));
    fit(MixedModel, varSlop, my_data; contrasts=my_cake);
  end

issingular(m_varyingSlope_zeroCorr)  # NOT overparameterized
VarCorr(m_varyingSlope_zeroCorr)
last(m_varyingSlope_zeroCorr.Î»)  # we only have one random effect: ID, but last() puts it into a nice matrix
# no zeroes on the diagonal

MixedModels.PCA(m_varyingSlope_zeroCorr)
```

Yes it does! We will find .. or zeores everywhere! \lambda is our actual variance-covariance matrix and we will only have number in the diagonal, perfect. VarCorr doesn't give us any correlation parameters and that is what we expected. PCA gave 0.0 everywhere except the diagonal.

#### Now how to delete one the correlation of Input_noise:Weak which is really low across the row when looking at the output of the PCA.
above in **Building new model without input_noiseW**
```{julia}

```

### Zero out coefficients with MixedModelsExtras.partial_fitted()
try out and see how it works...

## Actual model selection

### Likelihoodratiotest
must have same number of observations. Kliegl-Rule of thumb: if 2*chi.squared-dof > chi.squared then what was taken out was simple noise. Be parsimonious.

```{julia}
MixedModels.likelihoodratiotest(m_varyingSlope, m_varyingSlopeT)
```

We actually want to have no significant difference. In this case, we can simply go for the simpler model. If they are significantly different, we simply pay attention to the rule of thumb.
