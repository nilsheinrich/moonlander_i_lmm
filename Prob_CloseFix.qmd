---
title: "Nils Wendel Heinrich: all Fixations"
subtitle: "Moonlander I - Analysis"
author: "Nils Wendel Heinrich"
date: "2023-09-25"
format:
  html:
    embed-resources: true
    toc: true
    toc-depth: 2
    code-fold: false
    number-sections: true
    fig-width: 8
    fig-height: 6
editor_options:
  chunk_output_type: console
jupyter: julia-1.9
---

# Description
2 Covariates (continuous variables we believe affect the predicted variable) - N_visible_obstacles & N_visible_drift_tiles
1 Fixed Effect (categorical variable) - input noise

# Setup

## Packages

```{julia}
#| label: packages

using Arrow
using AlgebraOfGraphics
using CairoMakie
using DataFrames
using DataFrameMacros
using MixedModels
using MixedModelsMakie
using Random
#using RCall

CairoMakie.activate!(; type="svg");
```

```{julia}
#| label: constants
const RNG = MersenneTwister(36)
N_iterations = 10000
```

```{julia}
const AoG = AlgebraOfGraphics;
```

# Modeling fixation duration

## Code book
Two possible random effects: **ID** (the subject itself) and **total_control_loss** (whether subject reported having lost all control in specific situations).

```{julia}
#| label: data

my_data = DataFrame(Arrow.Table("data/Experiment1_FixationsComplete.arrow"))
my_data = dropmissing(my_data, [:N_visible_obstacles, :N_visible_drift_tiles])

# Filtering saccades with no amplitude
my_data = my_data[(my_data.fixation_duration .> 0.06), :]

describe(my_data)
```

### Contrasts

We will declare **ID** and **total_control_loss** as a grouping variable as well as define the effects coding for the discrete covariate input noise.

#### Hypothesis Coding
```{julia}
my_cake = Dict(
  :ID => Grouping(),
  :total_control_loss => Grouping(),
  :input_noise => HypothesisCoding(
    [
      -1 +1 0
      0 -1 +1
    ];
    levels=["N", "W", "S"],
    labels=["weak-none", "strong-weak"],
  ),
);
```

# Modeling fixation type
0: close fixation
1: distant fixation

We model the probability of initiating a close fixation vs. a distant fixation. We will account for a dichotomous predicted variable.

```{julia}
#| label: binary_outcome_variable

dist = Bernoulli()

```

## Building various models
```{julia}
#| label: m_varyingInt1

m_varyingInt1 = let
    formula = @formula(fixation_type ~ 1 + N_visible_obstacles * N_visible_drift_tiles + input_noise 
    + (1 | ID));
    fit(MixedModel, formula, my_data, dist; contrasts=my_cake);
  end

issingular(m_varyingInt1) # Not overparamterized
VarCorr(m_varyingInt1)
last(m_varyingInt1.λ)

```
ID might overexplain the predicted variable. We will still explore random slopes and be conservative regarding hypothesis testing.

### Exploring random slope effects
Probing random slopes until we arrive at a nonsingular model.

```{julia}
#| label: m_varyingSlope_

m_varyingSlope_ = let
    formula = @formula(fixation_type ~ 1 + N_visible_obstacles * N_visible_drift_tiles + input_noise 
    + (1 + N_visible_obstacles * N_visible_drift_tiles + input_noise | ID));
    fit(MixedModel, formula, my_data, dist; contrasts=my_cake);
  end

issingular(m_varyingSlope_) # Not overparamterized

```
already not overparameterized.

The following models will be tested against this one...

Stating no correlation between random effects.
```{julia}
#| label: m_varyingSlope__

m_varyingSlope__ = let
    formula = @formula(fixation_type ~ 1 + N_visible_obstacles * N_visible_drift_tiles + input_noise 
    + zerocorr(1 + N_visible_obstacles * N_visible_drift_tiles + input_noise | ID));
    fit(MixedModel, formula, my_data, dist; contrasts=my_cake);
  end

issingular(m_varyingSlope__) # Not overparamterized

```

```{julia}

gof_summary = let
  nms = [:m_varyingSlope_, :m_varyingSlope__]
  mods = eval.(nms)
  lrt = MixedModels.likelihoodratiotest(m_varyingSlope_, m_varyingSlope__)
  DataFrame(;
    name = nms, 
    dof=dof.(mods),
    deviance=round.(deviance.(mods), digits=0),
    AIC=round.(aic.(mods),digits=0),
    AICc=round.(aicc.(mods),digits=0),
    BIC=round.(bic.(mods),digits=0),
    χ²=vcat(:., round.(lrt.tests.deviancediff, digits=0)),
    χ²_dof=vcat(:., round.(lrt.tests.dofdiff, digits=0)),
    pvalue=vcat(:., round.(lrt.tests.pvalues, digits=3))
  )
end

```
Correlation between random effects has o be assumed (BIC).

without interaction term:
```{julia}
#| label: m_varyingSlope___

m_varyingSlope___ = let
    formula = @formula(fixation_type ~ 1 + N_visible_obstacles * N_visible_drift_tiles + input_noise 
    + (1 + N_visible_obstacles + N_visible_drift_tiles + input_noise | ID));
    fit(MixedModel, formula, my_data, dist; contrasts=my_cake);
  end

issingular(m_varyingSlope___) # Not overparamterized

```

```{julia}

gof_summary = let
  nms = [:m_varyingSlope_, :m_varyingSlope___]
  mods = eval.(nms)
  lrt = MixedModels.likelihoodratiotest(m_varyingSlope_, m_varyingSlope___)
  DataFrame(;
    name = nms, 
    dof=dof.(mods),
    deviance=round.(deviance.(mods), digits=0),
    AIC=round.(aic.(mods),digits=0),
    AICc=round.(aicc.(mods),digits=0),
    BIC=round.(bic.(mods),digits=0),
    χ²=vcat(:., round.(lrt.tests.deviancediff, digits=0)),
    χ²_dof=vcat(:., round.(lrt.tests.dofdiff, digits=0)),
    pvalue=vcat(:., round.(lrt.tests.pvalues, digits=3))
  )
end

```
Referring to BIC, the interaction term has to be kept as random slope.

without input noise
```{julia}
#| label: m_varyingSlope1

m_varyingSlope1 = let
    formula = @formula(fixation_type ~ 1 + N_visible_obstacles * N_visible_drift_tiles + input_noise 
    + (1 + N_visible_obstacles * N_visible_drift_tiles | ID));
    fit(MixedModel, formula, my_data, dist; contrasts=my_cake);
  end

issingular(m_varyingSlope1) # Not overparamterized

```

```{julia}

gof_summary = let
  nms = [:m_varyingSlope_, :m_varyingSlope1]
  mods = eval.(nms)
  lrt = MixedModels.likelihoodratiotest(m_varyingSlope_, m_varyingSlope1)
  DataFrame(;
    name = nms, 
    dof=dof.(mods),
    deviance=round.(deviance.(mods), digits=0),
    AIC=round.(aic.(mods),digits=0),
    AICc=round.(aicc.(mods),digits=0),
    BIC=round.(bic.(mods),digits=0),
    χ²=vcat(:., round.(lrt.tests.deviancediff, digits=0)),
    χ²_dof=vcat(:., round.(lrt.tests.dofdiff, digits=0)),
    pvalue=vcat(:., round.(lrt.tests.pvalues, digits=3))
  )
end

```
input_noise should be kept (BIC).

Deleting N_visible_drift_tiles
```{julia}
#| label: m_varyingSlope2

m_varyingSlope2 = let
    formula = @formula(fixation_type ~ 1 + N_visible_obstacles * N_visible_drift_tiles + input_noise 
    + (1 + N_visible_obstacles + input_noise | ID));
    fit(MixedModel, formula, my_data, dist; contrasts=my_cake);
  end

issingular(m_varyingSlope2) # Not overparamterized

```

```{julia}

gof_summary = let
  nms = [:m_varyingSlope_, :m_varyingSlope2]
  mods = eval.(nms)
  lrt = MixedModels.likelihoodratiotest(m_varyingSlope_, m_varyingSlope2)
  DataFrame(;
    name = nms, 
    dof=dof.(mods),
    deviance=round.(deviance.(mods), digits=0),
    AIC=round.(aic.(mods),digits=0),
    AICc=round.(aicc.(mods),digits=0),
    BIC=round.(bic.(mods),digits=0),
    χ²=vcat(:., round.(lrt.tests.deviancediff, digits=0)),
    χ²_dof=vcat(:., round.(lrt.tests.dofdiff, digits=0)),
    pvalue=vcat(:., round.(lrt.tests.pvalues, digits=3))
  )
end

```
Referring to BIC, N_visible_drift_tiles should be kept in the model.

Deleting N_visible_obstacles
```{julia}
#| label: m_varyingSlope3

m_varyingSlope3 = let
    formula = @formula(fixation_type ~ 1 + N_visible_obstacles * N_visible_drift_tiles + input_noise 
    + (1 + N_visible_drift_tiles + input_noise | ID));
    fit(MixedModel, formula, my_data, dist; contrasts=my_cake);
  end

issingular(m_varyingSlope3) # Not overparamterized

```

```{julia}

gof_summary = let
  nms = [:m_varyingSlope_, :m_varyingSlope3]
  mods = eval.(nms)
  lrt = MixedModels.likelihoodratiotest(m_varyingSlope_, m_varyingSlope3)
  DataFrame(;
    name = nms, 
    dof=dof.(mods),
    deviance=round.(deviance.(mods), digits=0),
    AIC=round.(aic.(mods),digits=0),
    AICc=round.(aicc.(mods),digits=0),
    BIC=round.(bic.(mods),digits=0),
    χ²=vcat(:., round.(lrt.tests.deviancediff, digits=0)),
    χ²_dof=vcat(:., round.(lrt.tests.dofdiff, digits=0)),
    pvalue=vcat(:., round.(lrt.tests.pvalues, digits=3))
  )
end

```
Referring to BIC, N_visible_obstacles should also be kept.

### Model selection
m_varyingSlope_, the complex model won out:
```{julia}
#| label: m_varyingSlope_ fitted with REML

m_varyingSlope_ = let
    formula = @formula(fixation_type ~ 1 + N_visible_obstacles * N_visible_drift_tiles + input_noise 
    + (1 + N_visible_obstacles * N_visible_drift_tiles | ID));
    fit(MixedModel, formula, my_data, dist; contrasts=my_cake);
  end
# REML=true not working...
VarCorr(m_varyingSlope_)

```

Due to zerocorr, no valuable information (but for the sake of completion):
```{julia}

MixedModels.PCA(m_varyingSlope_)

```

## Caterpillar plot
We can visually verify correlation between random effects.
```{julia}
#| fig-cap1: Prediction intervals on subject random effects for model m_varyingSlope_complex
#| label: fig-cm_varyingSlope
#|
cm_varyingSlope = first(ranefinfo(m_varyingSlope_));
caterpillar!(Figure(; resolution=(800, 1200)), cm_varyingSlope; orderby=1)
```

## Shrinkage plot

```{julia}
#| code-fold: true
#| label: fig-shrinkage
#|
#| fig-cap: Shrinkage plots of the subject random effects in the chosen model
shrinkageplot!(Figure(; resolution=(1000, 1200)), m_varyingSlope_)

```

## Main effects

```{julia}

m_varyingSlope_

```
We see **significant effects** for:
- N_visible_obstacles (β=-0.0621178, p<0.00)
- N_visible_drift_tiles (β=-0.283009, p=0.0068)
with both covariates **decreasing** the probability to to initiate a close fiation. 

Both covariates are positively correlated:
- N_visible_obstacles * N_visible_drift_tiles (β=0.0627916, p=0.0002)

honorable mentions:
- input_noise: weak-none (β=0.144008, p=0.0640)


without input noise as random slope:
N_visible_obstacles                          β=-0.0596801, p<1e-05
N_visible_drift_tiles                        β=-0.279864, p=0.0065
input_noise: weak-none                       β= 0.130239, p<1e-12
input_noise: strong-weak                     β=-0.0627505, p=0.0005
N_visible_obstacles & N_visible_drift_tiles  β= 0.0570189, p=0.0015


# Modeling fixation type with N_visible_obstacles as random intercept

```{julia}
#| label: m_test

m_test = let
    formula = @formula(fixation_type ~ 1 + N_visible_drift_tiles + input_noise 
    + (1 | ID)
    + (1 | N_visible_obstacles));
    fit(MixedModel, formula, my_data, dist; contrasts=my_cake);
  end

issingular(m_test) # Not overparamterized
#VarCorr(m_test)
#last(m_test.λ)

```

```{julia}
#| label: m_test_

m_test_ = let
    formula = @formula(fixation_type ~ 1 + N_visible_drift_tiles + input_noise 
    + (1 + N_visible_drift_tiles + input_noise | ID)
    + (1 + N_visible_drift_tiles + input_noise | N_visible_obstacles));
    fit(MixedModel, formula, my_data, dist; contrasts=my_cake);
  end

issingular(m_test_) # overparamterized!

```

Deleting N_visible_drift_tiles as random slope
```{julia}
#| label: m_test__

m_test__ = let
    formula = @formula(fixation_type ~ 1 + N_visible_drift_tiles + input_noise 
    + (1 + input_noise | ID)
    + (1 + input_noise | N_visible_obstacles));
    fit(MixedModel, formula, my_data, dist; contrasts=my_cake);
  end

issingular(m_test__) # Not overparamterized

```

Taking out input_noise
```{julia}
#| label: m_test___

m_test___ = let
    formula = @formula(fixation_type ~ 1 + N_visible_drift_tiles + input_noise 
    + (1 + N_visible_drift_tiles | ID)
    + (1 + N_visible_drift_tiles | N_visible_obstacles));
    fit(MixedModel, formula, my_data, dist; contrasts=my_cake);
  end

issingular(m_test___) # Not overparamterized

```

```{julia}

gof_summary = let
  nms = [:m_test, :m_test__, :m_test___]
  mods = eval.(nms)
  lrt = MixedModels.likelihoodratiotest(m_test, m_test__, m_test___)
  DataFrame(;
    name = nms, 
    dof=dof.(mods),
    deviance=round.(deviance.(mods), digits=0),
    AIC=round.(aic.(mods),digits=0),
    AICc=round.(aicc.(mods),digits=0),
    BIC=round.(bic.(mods),digits=0),
    χ²=vcat(:., round.(lrt.tests.deviancediff, digits=0)),
    χ²_dof=vcat(:., round.(lrt.tests.dofdiff, digits=0)),
    pvalue=vcat(:., round.(lrt.tests.pvalues, digits=3))
  )
end

```

### Model selection
m_varyingSlope_, the complex model won out:
```{julia}

m_test__

```
